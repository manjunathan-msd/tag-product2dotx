2024-08-27 08:02:26.003449: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-08-27 08:02:26.025552: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-08-27 08:02:26.031531: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-27 08:02:26.047999: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-27 08:02:26.955136: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Inferencing:   0%|          | 0/100 [00:00<?, ?it/s]Inferencing:   1%|          | 1/100 [00:20<33:26, 20.26s/it]Inferencing:   2%|▏         | 2/100 [00:38<32:08, 19.68s/it]Inferencing:   3%|▎         | 3/100 [00:57<31:29, 19.48s/it]Inferencing:   4%|▍         | 4/100 [01:16<31:00, 19.38s/it]Inferencing:   5%|▌         | 5/100 [01:29<27:46, 17.54s/it]Inferencing:   6%|▌         | 6/100 [01:45<26:20, 16.81s/it]Inferencing:   7%|▋         | 7/100 [02:06<28:24, 18.32s/it]Inferencing:   8%|▊         | 8/100 [02:26<28:30, 18.59s/it]Inferencing:   9%|▉         | 9/100 [02:47<29:23, 19.38s/it]Inferencing:  10%|█         | 10/100 [03:10<30:44, 20.50s/it]Inferencing:  11%|█         | 11/100 [03:32<31:00, 20.91s/it]Inferencing:  12%|█▏        | 12/100 [03:51<29:58, 20.44s/it]Inferencing:  13%|█▎        | 13/100 [04:11<29:24, 20.28s/it]Inferencing:  14%|█▍        | 14/100 [04:35<30:25, 21.23s/it]Inferencing:  15%|█▌        | 15/100 [04:51<28:07, 19.85s/it]Inferencing:  16%|█▌        | 16/100 [05:10<27:11, 19.43s/it]Inferencing:  17%|█▋        | 17/100 [05:29<26:43, 19.32s/it]Inferencing:  18%|█▊        | 18/100 [05:51<27:47, 20.33s/it]Inferencing:  19%|█▉        | 19/100 [06:11<27:09, 20.12s/it]Inferencing:  20%|██        | 20/100 [06:27<25:06, 18.83s/it]Inferencing:  21%|██        | 21/100 [06:44<24:14, 18.42s/it]Inferencing:  22%|██▏       | 22/100 [07:16<28:58, 22.29s/it]Inferencing:  23%|██▎       | 23/100 [07:41<29:41, 23.13s/it]Inferencing:  24%|██▍       | 24/100 [07:59<27:19, 21.57s/it]Inferencing:  25%|██▌       | 25/100 [08:16<25:14, 20.19s/it]Inferencing:  26%|██▌       | 26/100 [08:33<24:02, 19.49s/it]Inferencing:  27%|██▋       | 27/100 [08:54<24:14, 19.92s/it]Inferencing:  28%|██▊       | 28/100 [09:20<25:51, 21.55s/it]Inferencing:  29%|██▉       | 29/100 [09:35<23:23, 19.76s/it]Inferencing:  30%|███       | 30/100 [09:58<24:03, 20.63s/it]Inferencing:  31%|███       | 31/100 [10:18<23:39, 20.57s/it]Inferencing:  32%|███▏      | 32/100 [10:39<23:27, 20.70s/it]Inferencing:  33%|███▎      | 33/100 [11:01<23:23, 20.95s/it]Inferencing:  34%|███▍      | 34/100 [11:21<22:48, 20.74s/it]Inferencing:  35%|███▌      | 35/100 [11:40<21:53, 20.21s/it]Inferencing:  36%|███▌      | 36/100 [11:59<21:05, 19.78s/it]Inferencing:  37%|███▋      | 37/100 [12:15<19:33, 18.62s/it]Inferencing:  38%|███▊      | 38/100 [12:34<19:15, 18.64s/it]Inferencing:  39%|███▉      | 39/100 [12:57<20:23, 20.06s/it]Inferencing:  40%|████      | 40/100 [13:34<25:12, 25.21s/it]Inferencing:  41%|████      | 41/100 [13:53<22:49, 23.22s/it]Inferencing:  42%|████▏     | 42/100 [14:17<22:40, 23.46s/it]Inferencing:  43%|████▎     | 43/100 [14:36<21:04, 22.19s/it]Inferencing:  44%|████▍     | 44/100 [14:59<21:03, 22.55s/it]Inferencing:  45%|████▌     | 45/100 [15:22<20:39, 22.53s/it]Inferencing:  46%|████▌     | 46/100 [15:45<20:24, 22.67s/it]Inferencing:  47%|████▋     | 47/100 [16:06<19:36, 22.19s/it]Inferencing:  48%|████▊     | 48/100 [16:29<19:34, 22.59s/it]Inferencing:  49%|████▉     | 49/100 [16:52<19:05, 22.46s/it]Inferencing:  50%|█████     | 50/100 [17:17<19:24, 23.28s/it]Inferencing:  51%|█████     | 51/100 [17:33<17:13, 21.09s/it]Inferencing:  52%|█████▏    | 52/100 [17:53<16:40, 20.85s/it]Inferencing:  53%|█████▎    | 53/100 [18:11<15:36, 19.94s/it]Inferencing:  54%|█████▍    | 54/100 [18:31<15:13, 19.87s/it]Inferencing:  55%|█████▌    | 55/100 [18:58<16:39, 22.20s/it]Inferencing:  56%|█████▌    | 56/100 [19:29<18:10, 24.78s/it]Inferencing:  57%|█████▋    | 57/100 [19:52<17:18, 24.14s/it]Inferencing:  58%|█████▊    | 58/100 [20:13<16:20, 23.34s/it]Inferencing:  59%|█████▉    | 59/100 [20:32<15:05, 22.09s/it]Inferencing:  60%|██████    | 60/100 [20:56<15:05, 22.64s/it]Inferencing:  61%|██████    | 61/100 [21:14<13:46, 21.19s/it]Inferencing:  62%|██████▏   | 62/100 [21:32<12:50, 20.27s/it]Inferencing:  63%|██████▎   | 63/100 [21:53<12:39, 20.52s/it]Inferencing:  64%|██████▍   | 64/100 [22:17<12:55, 21.55s/it]Inferencing:  65%|██████▌   | 65/100 [22:38<12:22, 21.21s/it]Inferencing:  66%|██████▌   | 66/100 [22:58<11:50, 20.89s/it]Inferencing:  67%|██████▋   | 67/100 [23:17<11:15, 20.48s/it]Inferencing:  68%|██████▊   | 68/100 [23:34<10:20, 19.38s/it]Inferencing:  69%|██████▉   | 69/100 [23:54<10:04, 19.51s/it]Inferencing:  70%|███████   | 70/100 [24:15<09:56, 19.90s/it]Inferencing:  71%|███████   | 71/100 [24:31<09:09, 18.94s/it]Inferencing:  72%|███████▏  | 72/100 [24:48<08:30, 18.24s/it]Inferencing:  73%|███████▎  | 73/100 [25:12<08:55, 19.85s/it]Inferencing:  74%|███████▍  | 74/100 [25:28<08:10, 18.88s/it]Inferencing:  75%|███████▌  | 75/100 [25:47<07:53, 18.95s/it]Inferencing:  76%|███████▌  | 76/100 [26:05<07:27, 18.66s/it]Inferencing:  77%|███████▋  | 77/100 [26:25<07:16, 18.96s/it]Inferencing:  78%|███████▊  | 78/100 [26:47<07:15, 19.78s/it]Inferencing:  79%|███████▉  | 79/100 [27:07<06:56, 19.85s/it]Inferencing:  80%|████████  | 80/100 [27:30<06:59, 21.00s/it]Inferencing:  81%|████████  | 81/100 [27:49<06:26, 20.34s/it]Inferencing:  82%|████████▏ | 82/100 [28:11<06:11, 20.64s/it]Inferencing:  83%|████████▎ | 83/100 [28:34<06:04, 21.46s/it]Inferencing:  84%|████████▍ | 84/100 [28:54<05:38, 21.17s/it]Inferencing:  85%|████████▌ | 85/100 [29:14<05:09, 20.66s/it]Inferencing:  86%|████████▌ | 86/100 [29:35<04:50, 20.77s/it]Inferencing:  87%|████████▋ | 87/100 [29:54<04:21, 20.13s/it]Inferencing:  88%|████████▊ | 88/100 [30:13<03:59, 19.94s/it]Inferencing:  89%|████████▉ | 89/100 [30:31<03:32, 19.33s/it]Inferencing:  90%|█████████ | 90/100 [30:50<03:13, 19.36s/it]Inferencing:  91%|█████████ | 91/100 [31:07<02:47, 18.62s/it]Inferencing:  92%|█████████▏| 92/100 [31:28<02:33, 19.25s/it]Inferencing:  93%|█████████▎| 93/100 [31:47<02:14, 19.18s/it]Inferencing:  94%|█████████▍| 94/100 [32:02<01:48, 18.02s/it]Inferencing:  95%|█████████▌| 95/100 [32:22<01:31, 18.39s/it]Inferencing:  96%|█████████▌| 96/100 [32:41<01:14, 18.60s/it]Inferencing:  97%|█████████▋| 97/100 [33:03<00:59, 19.80s/it]Inferencing:  98%|█████████▊| 98/100 [33:31<00:44, 22.10s/it]Inferencing:  99%|█████████▉| 99/100 [33:56<00:23, 23.11s/it]Inferencing: 100%|██████████| 100/100 [34:19<00:00, 23.07s/it]Inferencing: 100%|██████████| 100/100 [34:19<00:00, 20.60s/it]
